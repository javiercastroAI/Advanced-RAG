{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ebd5f5-2328-476e-9589-c80fd0cfb1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No references provided → auto-generating short references from corpus for recall/precision.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**### CONFIG**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| Key         | Value                                                                                                                                                                                                |\n",
       "|:------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
       "| embedding   | text-embedding-3-small                                                                                                                                                                               |\n",
       "| llm         | gpt-4o-mini                                                                                                                                                                                          |\n",
       "| ragas_llm   | gpt-4o-mini                                                                                                                                                                                          |\n",
       "| ragas_emb   | text-embedding-3-small                                                                                                                                                                               |\n",
       "| experiments | ['baseline-vector (vector)', 'sentence-window (sentence_window)', 'auto-merging (auto_merging)', 'sentence-window+rerank (sentence_window) + rerank', 'auto-merging+rerank (auto_merging) + rerank'] |\n",
       "| questions   | 4                                                                                                                                                                                                    |\n",
       "| references  | provided                                                                                                                                                                                             |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRACES (Question ➜ Answer by experiment) ===\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "--- Experiment: baseline-vector  | retriever=vector  | rerank=off ---\n",
      "\n",
      "Q1: What concrete steps does the document recommend for finding projects to work on?\n",
      "A1: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on. It emphasizes the importance of showcasing real, runnable things instead of vague portfolios.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on.\n",
      "\n",
      "Q2: How should a newcomer prioritise learning versus shipping projects, according to the text?\n",
      "A2: A newcomer should prioritize shipping small projects while simultaneously learning and networking. This approach emphasizes the importance of demonstrating real, runnable work rather than maintaining a vague portfolio.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: A newcomer should prioritize shipping small projects while learning in public, as indicated in the text.\n",
      "\n",
      "Q3: What pitfalls does the text warn about when building a portfolio?\n",
      "A3: The text warns against creating vague portfolios and emphasizes the importance of showcasing real, runnable projects. \n",
      "\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The text warns against creating vague portfolios and emphasizes the importance of showing real, runnable projects.\n",
      "\n",
      "Q4: Summarise the recommended networking tactics.\n",
      "A4: To build a career in AI, it is recommended to ship small projects, learn in public, and network kindly. Avoid vague portfolios and instead showcase real, runnable projects.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The recommended networking tactics are to network kindly.\n",
      "\n",
      "--- Experiment: sentence-window  | retriever=sentence_window  | rerank=off ---\n",
      "\n",
      "Q1: What concrete steps does the document recommend for finding projects to work on?\n",
      "A1: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on. It emphasizes the importance of showcasing real, runnable work rather than vague portfolios.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#2]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#1]\n",
      "Ref: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on.\n",
      "\n",
      "Q2: How should a newcomer prioritise learning versus shipping projects, according to the text?\n",
      "A2: A newcomer should prioritize shipping small projects while simultaneously learning and networking. This approach allows them to gain practical experience and visibility in their field.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#1]\n",
      "Ref: A newcomer should prioritize shipping small projects while learning in public, as indicated in the text.\n",
      "\n",
      "Q3: What pitfalls does the text warn about when building a portfolio?\n",
      "A3: The text warns against creating vague portfolios and emphasizes the importance of showcasing real, runnable projects. It suggests that building a portfolio should involve tangible work rather than abstract ideas.\n",
      "\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The text warns against creating vague portfolios and emphasizes the importance of showing real, runnable projects.\n",
      "\n",
      "Q4: Summarise the recommended networking tactics.\n",
      "A4: To effectively network, it is recommended to ship small projects, learn in public, and engage with others kindly. Additionally, it is important to avoid vague portfolios and instead showcase real, runnable projects.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#1]\n",
      "Ref: The recommended networking tactics are to network kindly.\n",
      "\n",
      "--- Experiment: auto-merging  | retriever=auto_merging  | rerank=off ---\n",
      "\n",
      "Q1: What concrete steps does the document recommend for finding projects to work on?\n",
      "A1: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on. It emphasizes the importance of showcasing real, runnable things instead of vague portfolios.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on.\n",
      "\n",
      "Q2: How should a newcomer prioritise learning versus shipping projects, according to the text?\n",
      "A2: A newcomer should prioritize shipping small projects while simultaneously learning and networking. This approach allows them to demonstrate their skills through tangible work rather than vague portfolios.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: A newcomer should prioritize shipping small projects while learning in public, as indicated in the text.\n",
      "\n",
      "Q3: What pitfalls does the text warn about when building a portfolio?\n",
      "A3: The text warns against creating vague portfolios and emphasizes the importance of showcasing real, runnable projects. \n",
      "\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The text warns against creating vague portfolios and emphasizes the importance of showing real, runnable projects.\n",
      "\n",
      "Q4: Summarise the recommended networking tactics.\n",
      "A4: To build a career in AI, it is recommended to ship small projects, learn in public, and network kindly. Avoid vague portfolios and instead showcase real, runnable projects.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The recommended networking tactics are to network kindly.\n",
      "\n",
      "--- Experiment: sentence-window+rerank  | retriever=sentence_window  | rerank=on ---\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "Q1: What concrete steps does the document recommend for finding projects to work on?\n",
      "A1: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on. It emphasizes the importance of avoiding vague portfolios by showcasing real, runnable projects.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#1]\n",
      "Ref: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on.\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "Q2: How should a newcomer prioritise learning versus shipping projects, according to the text?\n",
      "A2: A newcomer should prioritize shipping small projects while simultaneously learning and networking. This approach allows for practical experience and visibility in the field.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#1]\n",
      "Ref: A newcomer should prioritize shipping small projects while learning in public, as indicated in the text.\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "Q3: What pitfalls does the text warn about when building a portfolio?\n",
      "A3: The text warns against creating vague portfolios and emphasizes the importance of showcasing real, runnable projects. It suggests that building a portfolio should involve tangible work rather than abstract concepts.\n",
      "\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The text warns against creating vague portfolios and emphasizes the importance of showing real, runnable projects.\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "Q4: Summarise the recommended networking tactics.\n",
      "A4: To effectively network, it is recommended to ship small projects, learn in public, and engage in kind networking. Additionally, it is important to avoid vague portfolios and instead showcase real, runnable projects.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#1]\n",
      "Ref: The recommended networking tactics are to network kindly.\n",
      "\n",
      "--- Experiment: auto-merging+rerank  | retriever=auto_merging  | rerank=on ---\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "Q1: What concrete steps does the document recommend for finding projects to work on?\n",
      "A1: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on. It emphasizes the importance of showcasing real, runnable things instead of vague portfolios.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The document recommends shipping small projects, learning in public, and networking kindly as concrete steps for finding projects to work on.\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "Q2: How should a newcomer prioritise learning versus shipping projects, according to the text?\n",
      "A2: A newcomer should prioritize shipping small projects while simultaneously learning and networking. This approach emphasizes the importance of demonstrating real, runnable work rather than maintaining a vague portfolio.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: A newcomer should prioritize shipping small projects while learning in public, as indicated in the text.\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "Q3: What pitfalls does the text warn about when building a portfolio?\n",
      "A3: The text warns against creating vague portfolios and emphasizes the importance of showcasing real, runnable projects. \n",
      "\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The text warns against creating vague portfolios and emphasizes the importance of showing real, runnable projects.\n",
      "[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\n",
      "\n",
      "Q4: Summarise the recommended networking tactics.\n",
      "A4: To build a career in AI, it is recommended to ship small projects, learn in public, and network kindly. Avoid vague portfolios and instead showcase real, runnable projects.\n",
      "\n",
      "- \"Ship small projects, learn in public, and network kindly.\" [#0]\n",
      "- \"Avoid vague portfolios; show real, runnable things.\" [#0]\n",
      "Ref: The recommended networking tactics are to network kindly.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**### EVALUATION (per-sample progress)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• baseline-vector  |  What concrete steps does the document recommend for finding proj…  |  Answer Relevance=1.000, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• baseline-vector  |  How should a newcomer prioritise learning versus shipping projec…  |  Answer Relevance=0.582, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• baseline-vector  |  What pitfalls does the text warn about when building a portfolio…  |  Answer Relevance=0.754, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• baseline-vector  |  Summarise the recommended networking tactics.…  |  Answer Relevance=0.288, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• sentence-window  |  What concrete steps does the document recommend for finding proj…  |  Answer Relevance=1.000, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=0.333</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• sentence-window  |  How should a newcomer prioritise learning versus shipping projec…  |  Answer Relevance=0.582, Faithfulness (≈ Groundedness)=0.714, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• sentence-window  |  What pitfalls does the text warn about when building a portfolio…  |  Answer Relevance=0.769, Faithfulness (≈ Groundedness)=0.833, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• sentence-window  |  Summarise the recommended networking tactics.…  |  Answer Relevance=0.589, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• auto-merging  |  What concrete steps does the document recommend for finding proj…  |  Answer Relevance=1.000, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• auto-merging  |  How should a newcomer prioritise learning versus shipping projec…  |  Answer Relevance=0.584, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• auto-merging  |  What pitfalls does the text warn about when building a portfolio…  |  Answer Relevance=0.754, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• auto-merging  |  Summarise the recommended networking tactics.…  |  Answer Relevance=0.288, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• sentence-window+rerank  |  What concrete steps does the document recommend for finding proj…  |  Answer Relevance=1.000, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• sentence-window+rerank  |  How should a newcomer prioritise learning versus shipping projec…  |  Answer Relevance=0.578, Faithfulness (≈ Groundedness)=0.714, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• sentence-window+rerank  |  What pitfalls does the text warn about when building a portfolio…  |  Answer Relevance=0.752, Faithfulness (≈ Groundedness)=0.833, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• sentence-window+rerank  |  Summarise the recommended networking tactics.…  |  Answer Relevance=0.590, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• auto-merging+rerank  |  What concrete steps does the document recommend for finding proj…  |  Answer Relevance=1.000, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• auto-merging+rerank  |  How should a newcomer prioritise learning versus shipping projec…  |  Answer Relevance=0.602, Faithfulness (≈ Groundedness)=0.833, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• auto-merging+rerank  |  What pitfalls does the text warn about when building a portfolio…  |  Answer Relevance=0.754, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**<small>• auto-merging+rerank  |  Summarise the recommended networking tactics.…  |  Answer Relevance=0.288, Faithfulness (≈ Groundedness)=1.000, Context Recall=1.000, Context Precision=1.000</small>**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**### RAGAS Leaderboard (means)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| experiment             | retriever       |   Answer Relevance |   Faithfulness (≈ Groundedness) |   Context Recall |   Context Precision |\n",
       "|:-----------------------|:----------------|-------------------:|--------------------------------:|-----------------:|--------------------:|\n",
       "| auto-merging           | auto_merging    |           0.656498 |                        1        |                1 |            1        |\n",
       "| auto-merging+rerank    | auto_merging    |           0.66113  |                        0.958333 |                1 |            1        |\n",
       "| baseline-vector        | vector          |           0.656055 |                        1        |                1 |            1        |\n",
       "| sentence-window        | sentence_window |           0.735091 |                        0.886905 |                1 |            0.833333 |\n",
       "| sentence-window+rerank | sentence_window |           0.729676 |                        0.886905 |                1 |            1        |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**### Per-question Scores (Markdown)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| experiment             | retriever       | question                                                                                   |   Answer Relevance |   Faithfulness (≈ Groundedness) |   Context Recall |   Context Precision |\n",
       "|:-----------------------|:----------------|:-------------------------------------------------------------------------------------------|-------------------:|--------------------------------:|-----------------:|--------------------:|\n",
       "| baseline-vector        | vector          | What concrete steps does the document recommend for finding projects to work on?           |           1        |                        1        |                1 |            1        |\n",
       "| baseline-vector        | vector          | How should a newcomer prioritise learning versus shipping projects, according to the text? |           0.582144 |                        1        |                1 |            1        |\n",
       "| baseline-vector        | vector          | What pitfalls does the text warn about when building a portfolio?                          |           0.754002 |                        1        |                1 |            1        |\n",
       "| baseline-vector        | vector          | Summarise the recommended networking tactics.                                              |           0.288076 |                        1        |                1 |            1        |\n",
       "| sentence-window        | sentence_window | What concrete steps does the document recommend for finding projects to work on?           |           1        |                        1        |                1 |            0.333333 |\n",
       "| sentence-window        | sentence_window | How should a newcomer prioritise learning versus shipping projects, according to the text? |           0.581859 |                        0.714286 |                1 |            1        |\n",
       "| sentence-window        | sentence_window | What pitfalls does the text warn about when building a portfolio?                          |           0.769015 |                        0.833333 |                1 |            1        |\n",
       "| sentence-window        | sentence_window | Summarise the recommended networking tactics.                                              |           0.589488 |                        1        |                1 |            1        |\n",
       "| auto-merging           | auto_merging    | What concrete steps does the document recommend for finding projects to work on?           |           1        |                        1        |                1 |            1        |\n",
       "| auto-merging           | auto_merging    | How should a newcomer prioritise learning versus shipping projects, according to the text? |           0.583928 |                        1        |                1 |            1        |\n",
       "| auto-merging           | auto_merging    | What pitfalls does the text warn about when building a portfolio?                          |           0.753991 |                        1        |                1 |            1        |\n",
       "| auto-merging           | auto_merging    | Summarise the recommended networking tactics.                                              |           0.288073 |                        1        |                1 |            1        |\n",
       "| sentence-window+rerank | sentence_window | What concrete steps does the document recommend for finding projects to work on?           |           1        |                        1        |                1 |            1        |\n",
       "| sentence-window+rerank | sentence_window | How should a newcomer prioritise learning versus shipping projects, according to the text? |           0.577576 |                        0.714286 |                1 |            1        |\n",
       "| sentence-window+rerank | sentence_window | What pitfalls does the text warn about when building a portfolio?                          |           0.751598 |                        0.833333 |                1 |            1        |\n",
       "| sentence-window+rerank | sentence_window | Summarise the recommended networking tactics.                                              |           0.58953  |                        1        |                1 |            1        |\n",
       "| auto-merging+rerank    | auto_merging    | What concrete steps does the document recommend for finding projects to work on?           |           0.999989 |                        1        |                1 |            1        |\n",
       "| auto-merging+rerank    | auto_merging    | How should a newcomer prioritise learning versus shipping projects, according to the text? |           0.602485 |                        0.833333 |                1 |            1        |\n",
       "| auto-merging+rerank    | auto_merging    | What pitfalls does the text warn about when building a portfolio?                          |           0.753991 |                        1        |                1 |            1        |\n",
       "| auto-merging+rerank    | auto_merging    | Summarise the recommended networking tactics.                                              |           0.288055 |                        1        |                1 |            1        |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**### Experiments Summary (Markdown)**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| Experiment             | Retriever       |   TopK | Rerank   |   Window | Reranker Type   | Rerank Model        |   Rerank TopN |\n",
       "|:-----------------------|:----------------|-------:|:---------|---------:|:----------------|:--------------------|--------------:|\n",
       "| baseline-vector        | vector          |      6 | off      |      nan | nan             | nan                 |           nan |\n",
       "| sentence-window        | sentence_window |      6 | off      |        3 | nan             | nan                 |           nan |\n",
       "| auto-merging           | auto_merging    |      6 | off      |      nan | nan             | nan                 |           nan |\n",
       "| sentence-window+rerank | sentence_window |     50 | on       |        3 | cohere          | rerank-english-v3.0 |             8 |\n",
       "| auto-merging+rerank    | auto_merging    |     50 | on       |      nan | cohere          | rerank-english-v3.0 |             8 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Saved] traces → outputs/traces_all.csv  |  raw scores → outputs/ragas_raw_scores.csv  |  leaderboard → outputs/ragas_leaderboard.csv\n"
     ]
    }
   ],
   "source": [
    "# dnAI Javier Castro 20/09/25\n",
    "# ----------------------------------------------------------------\n",
    "# Advanced RAG EVALs sentence window, auto merging, reranking. Contex precision/recall answer relevance and groundesness=faithfulness\n",
    "# ----------------------------------------------------------------\n",
    "import os, sys, json, logging, warnings, subprocess, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "# 0) Bootstrap compatible deps\n",
    "def _ensure(pkgs):\n",
    "    to_install=[]\n",
    "    for mod, spec in pkgs:\n",
    "        try: __import__(mod)\n",
    "        except Exception: to_install.append(spec)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + to_install)\n",
    "\n",
    "_ensure([\n",
    "    (\"llama_index\", \"llama-index>=0.10.0\"),\n",
    "    (\"llama_index.llms.openai\", \"llama-index-llms-openai>=0.2.0\"),\n",
    "    (\"llama_index.embeddings.openai\", \"llama-index-embeddings-openai>=0.2.0\"),\n",
    "    (\"ragas\", \"ragas>=0.1.9\"),\n",
    "    (\"pandas\", \"pandas>=2.0.0\"),\n",
    "    (\"tabulate\", \"tabulate>=0.9.0\"),\n",
    "    (\"openai\", \"openai>=1.40.0\"),\n",
    "])\n",
    "\n",
    "try:\n",
    "    import cohere\n",
    "    _COHERE_AVAILABLE = True\n",
    "except Exception:\n",
    "    _COHERE_AVAILABLE = False\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.WARNING, force=True)\n",
    "for _name in (\"openai\", \"httpx\", \"httpcore\", \"ragas\", \"llama_index\"):\n",
    "    logging.getLogger(_name).setLevel(logging.WARNING)\n",
    "\n",
    "# Keep RAGAS quiet & robust\n",
    "os.environ.setdefault(\"RAGAS_DISABLE_ANALYTICS\", \"1\")\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "# 1) Imports\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from openai import OpenAI as OpenAIClient\n",
    "\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI as LlamaOpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "\n",
    "from ragas import evaluate\n",
    "import ragas.metrics as RM\n",
    "from ragas.metrics import faithfulness as FAITH\n",
    "try:\n",
    "    from ragas.run_config import RunConfig\n",
    "except Exception:\n",
    "    RunConfig = None\n",
    "from ragas.llms import llm_factory\n",
    "\n",
    "# --- Markdown/HTML helpers (work in notebooks; graceful fallback in terminals) ---\n",
    "_IS_NOTEBOOK = False\n",
    "try:\n",
    "    from IPython.display import display, Markdown\n",
    "    _IS_NOTEBOOK = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "def md_line(text: str, small: bool = False, bold: bool = False):\n",
    "    \"\"\"Print a single markdown line; in notebooks render markdown, else print raw.\"\"\"\n",
    "    s = text\n",
    "    if small:\n",
    "        s = f\"<small>{s}</small>\"\n",
    "    if bold:\n",
    "        s = f\"**{s}**\"\n",
    "    if _IS_NOTEBOOK:\n",
    "        try:\n",
    "            display(Markdown(s))\n",
    "            return\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(s)\n",
    "\n",
    "def md_table(markdown_table_str: str, title: Optional[str] = None, small: bool = False, bold: bool = False):\n",
    "    \"\"\"Render a full markdown table string nicely; in terminals falls back to print.\"\"\"\n",
    "    if title:\n",
    "        md_line(title, bold=True)\n",
    "    s = markdown_table_str\n",
    "    if small:\n",
    "        s = f\"<small>\\n{s}\\n</small>\"\n",
    "    if bold:\n",
    "        s = f\"**\\n{s}\\n**\"\n",
    "    if _IS_NOTEBOOK:\n",
    "        try:\n",
    "            display(Markdown(s))\n",
    "            return\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(s)\n",
    "\n",
    "# 2) Config\n",
    "CONFIG = {\n",
    "    \"data_path\": \"./data\",\n",
    "    \"create_sample_if_empty\": True,\n",
    "    \"eval_questions\": [\n",
    "        \"What concrete steps does the document recommend for finding projects to work on?\",\n",
    "        \"How should a newcomer prioritise learning versus shipping projects, according to the text?\",\n",
    "        \"What pitfalls does the text warn about when building a portfolio?\",\n",
    "        \"Summarise the recommended networking tactics.\"\n",
    "    ],\n",
    "    # If empty, we'll auto-generate short references from the corpus (needed for recall/precision)\n",
    "    \"eval_references\": [],\n",
    "    \"embedding\": {\"model\": \"text-embedding-3-small\"},\n",
    "    \"llm\": {\"model\": \"gpt-4o-mini\", \"temperature\": 0.0},\n",
    "    \"experiments\": [\n",
    "        {\"name\": \"baseline-vector\",        \"retriever\": \"vector\",          \"top_k\": 6},\n",
    "        {\"name\": \"sentence-window\",        \"retriever\": \"sentence_window\", \"window_size\": 3, \"top_k\": 6},\n",
    "        {\"name\": \"auto-merging\",           \"retriever\": \"auto_merging\",    \"top_k\": 6},\n",
    "        {\"name\": \"sentence-window+rerank\", \"retriever\": \"sentence_window\", \"window_size\": 3, \"top_k\": 50,\n",
    "         \"reranker\": {\"type\": \"cohere\", \"top_n\": 8, \"model\": \"rerank-english-v3.0\"}},\n",
    "        {\"name\": \"auto-merging+rerank\",    \"retriever\": \"auto_merging\",    \"top_k\": 50,\n",
    "         \"reranker\": {\"type\": \"cohere\", \"top_n\": 8, \"model\": \"rerank-english-v3.0\"}},\n",
    "    ],\n",
    "    \"ragas\": {\"llm_model\": \"gpt-4o-mini\", \"embed_model\": \"text-embedding-3-small\"},\n",
    "    \"output_dir\": \"./outputs\",\n",
    "    \"print_context_chars\": 0,\n",
    "}\n",
    "\n",
    "# 3) Builders & utilities\n",
    "def _ensure_dir(p: str): Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _maybe_create_sample(data_path: str):\n",
    "    d = Path(data_path); d.mkdir(parents=True, exist_ok=True)\n",
    "    if not any(d.rglob(\"*\")):\n",
    "        (d / \"sample.txt\").write_text(\n",
    "            \"This is a tiny sample document about career building in AI. \"\n",
    "            \"Ship small projects, learn in public, and network kindly. \"\n",
    "            \"Avoid vague portfolios; show real, runnable things. \"\n",
    "            \"Concrete steps: pick a small problem, scope it to a weekend, build an MVP, and share a demo write-up.\"\n",
    "        )\n",
    "\n",
    "def _load_corpus(data_path: str):\n",
    "    docs = SimpleDirectoryReader(input_dir=data_path, recursive=True).load_data()\n",
    "    if not docs:\n",
    "        raise RuntimeError(f\"No documents found under: {data_path}\")\n",
    "    return docs\n",
    "\n",
    "def _build_embedder(cfg): return OpenAIEmbedding(model=cfg.get(\"model\", \"text-embedding-3-small\"))\n",
    "def _build_llm(cfg): return LlamaOpenAI(model=cfg.get(\"model\", \"gpt-4o-mini\"), temperature=cfg.get(\"temperature\", 0.0))\n",
    "\n",
    "class OpenAIEmbeddingsAdapter:\n",
    "    \"\"\"Minimal adapter providing the methods RAGAS expects (embed_query/documents).\"\"\"\n",
    "    def __init__(self, client: OpenAIClient, model: str):\n",
    "        self.client = client; self.model = model\n",
    "    def embed_query(self, text: str):\n",
    "        return self.client.embeddings.create(model=self.model, input=text).data[0].embedding\n",
    "    def embed_documents(self, texts: List[str]):\n",
    "        return [self.embed_query(t) for t in texts]\n",
    "\n",
    "def _build_vector_retriever(docs, embed_model, top_k):\n",
    "    index = VectorStoreIndex.from_documents(docs, embed_model=embed_model)\n",
    "    return index.as_retriever(similarity_top_k=top_k), index\n",
    "\n",
    "def _build_sentence_window_retriever(docs, embed_model, window_size, top_k):\n",
    "    parser = SentenceWindowNodeParser.from_defaults(window_size=window_size)\n",
    "    nodes = parser.get_nodes_from_documents(docs)\n",
    "    index = VectorStoreIndex(nodes, embed_model=embed_model)\n",
    "    return index.as_retriever(similarity_top_k=top_k), index\n",
    "\n",
    "def _build_auto_merging_retriever(docs, embed_model, top_k):\n",
    "    index = VectorStoreIndex.from_documents(docs, embed_model=embed_model)\n",
    "    base = index.as_retriever(similarity_top_k=top_k)\n",
    "    am = AutoMergingRetriever(base, index.storage_context)\n",
    "    return am, index\n",
    "\n",
    "def _cosine(u: List[float], v: List[float]) -> float:\n",
    "    dot = sum(a*b for a,b in zip(u,v))\n",
    "    nu = (sum(a*a for a in u)) ** 0.5 or 1.0\n",
    "    nv = (sum(b*b for b in v)) ** 0.5 or 1.0\n",
    "    return dot/(nu*nv)\n",
    "\n",
    "def _cohere_rerank(question: str, texts: List[str], top_n: int, model: str) -> List[int]:\n",
    "    api_key = os.environ.get(\"COHERE_API_KEY\")\n",
    "    if not (_COHERE_AVAILABLE and api_key):\n",
    "        raise RuntimeError(\"Cohere not available\")\n",
    "    c = cohere.Client(api_key)\n",
    "    res = c.rerank(model=model, query=question, documents=texts, top_n=min(top_n, len(texts)))\n",
    "    return [r.index for r in res.results]\n",
    "\n",
    "def _emb_rerank(question: str, texts: List[str], top_n: int, emb_adapter) -> List[int]:\n",
    "    qv = emb_adapter.embed_query(question)\n",
    "    dvs = emb_adapter.embed_documents(texts)\n",
    "    order = sorted(range(len(texts)), key=lambda i: _cosine(qv, dvs[i]), reverse=True)\n",
    "    return order[:min(top_n, len(order))]\n",
    "\n",
    "def _llm_batch_rerank(question: str, texts: List[str], top_n: int, client: OpenAIClient, model=\"gpt-4o-mini\") -> List[int]:\n",
    "    if not texts: return []\n",
    "    prompt = (\n",
    "        \"You are a reranker. Given a QUESTION and numbered PASSAGES, return JSON {\\\"top_indices\\\":[...]} \"\n",
    "        f\"for the top {min(top_n, len(texts))} most relevant in descending order.\\n\\n\"\n",
    "        f\"QUESTION:\\n{question}\\n\\nPASSAGES:\\n\" +\n",
    "        \"\\n\".join([f\"[{i}] {t[:1500]}\" for i,t in enumerate(texts)])\n",
    "    )\n",
    "    out = client.chat.completions.create(model=model, messages=[{\"role\":\"user\",\"content\":prompt}], temperature=0)\n",
    "    txt = out.choices[0].message.content.strip()\n",
    "    try:\n",
    "        data = json.loads(txt)\n",
    "        idxs = [int(i) for i in data.get(\"top_indices\", []) if 0 <= int(i) < len(texts)]\n",
    "        if idxs: return idxs[:min(top_n, len(idxs))]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return _emb_rerank(question, texts, top_n, OpenAIEmbeddingsAdapter(client, \"text-embedding-3-small\"))\n",
    "\n",
    "def _apply_rerank(question: str, nodes, rer_cfg: Optional[Dict[str, Any]], client: OpenAIClient):\n",
    "    if not rer_cfg or not nodes: return nodes\n",
    "    texts=[]\n",
    "    for sn in nodes:\n",
    "        n = getattr(sn, \"node\", None) or sn\n",
    "        t = getattr(n, \"text\", None) or getattr(n, \"get_text\", lambda: None)()\n",
    "        texts.append(t or \"\")\n",
    "    top_n = int(rer_cfg.get(\"top_n\", 8))\n",
    "    rtype  = (rer_cfg.get(\"type\") or \"llm\").lower()\n",
    "    try:\n",
    "        if rtype == \"cohere\":\n",
    "            idxs = _cohere_rerank(question, texts, top_n, rer_cfg.get(\"model\", \"rerank-english-v3.0\"))\n",
    "        else:\n",
    "            idxs = _llm_batch_rerank(question, texts, top_n, client)\n",
    "    except Exception:\n",
    "        print(\"[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\")\n",
    "        sys.stdout.flush()\n",
    "        idxs = _llm_batch_rerank(question, texts, top_n, client)\n",
    "    return [nodes[i] for i in idxs]\n",
    "\n",
    "def _answer_extractive(question: str, contexts: List[str], client: OpenAIClient, model=\"gpt-4o-mini\") -> Tuple[str, List[str]]:\n",
    "    sys_msg = {\"role\": \"system\", \"content\": (\n",
    "        \"You are an extractive assistant. Answer ONLY using the provided snippets. \"\n",
    "        \"Quote exact lines (with [#idx]) that support each claim. If insufficient info, say you don't know.\"\n",
    "    )}\n",
    "    user_msg = {\"role\": \"user\", \"content\": (\n",
    "        f\"QUESTION:\\n{question}\\n\\n\"\n",
    "        \"SNIPPETS (numbered):\\n\" + \"\\n\".join([f\"[{i}] {c}\" for i,c in enumerate(contexts)]) +\n",
    "        \"\\n\\nReturn:\\n- 1–3 sentence answer.\\n- Bullet list of quoted evidence with [#idx].\\n\"\n",
    "    )}\n",
    "    out = client.chat.completions.create(model=model, messages=[sys_msg, user_msg], temperature=0)\n",
    "    return out.choices[0].message.content.strip(), contexts\n",
    "\n",
    "def _generate_references_from_corpus(docs, questions: List[str], client: OpenAIClient, model=\"gpt-4o-mini\", max_chars=16000) -> List[str]:\n",
    "    corpus = \"\\n\\n\".join(getattr(d, \"text\", \"\") for d in docs)[:max_chars]\n",
    "    refs=[]\n",
    "    for q in questions:\n",
    "        out = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\":\"system\",\"content\":\"Answer concisely (<=100 words) using ONLY the provided corpus.\"},\n",
    "                {\"role\":\"user\",\"content\":f\"CORPUS:\\n{corpus}\\n\\nQUESTION:\\n{q}\\n\\nReturn a concise, factual reference answer grounded only in the corpus.\"}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        refs.append(out.choices[0].message.content.strip())\n",
    "    return refs\n",
    "\n",
    "def _make_answer_relevance_metric(ragas_llm, ragas_emb):\n",
    "    try:\n",
    "        from ragas.metrics.answer_relevancy import AnswerRelevancy\n",
    "        return AnswerRelevancy(llm=ragas_llm, embeddings=ragas_emb)\n",
    "    except Exception: pass\n",
    "    try:\n",
    "        from ragas.metrics.answer_relevance import AnswerRelevance\n",
    "        return AnswerRelevance(llm=ragas_llm, embeddings=ragas_emb)\n",
    "    except Exception: pass\n",
    "    for name in (\"answer_relevancy\", \"answer_relevance\"):\n",
    "        m = getattr(RM, name, None)\n",
    "        if m is not None:\n",
    "            if hasattr(m, \"llm\"): setattr(m, \"llm\", ragas_llm)\n",
    "            if hasattr(m, \"embeddings\"): setattr(m, \"embeddings\", ragas_emb)\n",
    "            return m\n",
    "    return None\n",
    "\n",
    "def _bind_models_to_metrics(metrics, ragas_llm, ragas_emb):\n",
    "    for m in metrics:\n",
    "        if hasattr(m, \"llm\") and getattr(m, \"llm\", None) is None:\n",
    "            try: setattr(m, \"llm\", ragas_llm)\n",
    "            except Exception: pass\n",
    "        if hasattr(m, \"embeddings\") and getattr(m, \"embeddings\", None) is None:\n",
    "            try: setattr(m, \"embeddings\", ragas_emb)\n",
    "            except Exception: pass\n",
    "        if hasattr(m, \"set_llm\"):\n",
    "            try: m.set_llm(ragas_llm)\n",
    "            except Exception: pass\n",
    "        if hasattr(m, \"set_embeddings\"):\n",
    "            try: m.set_embeddings(ragas_emb)\n",
    "            except Exception: pass\n",
    "    return metrics\n",
    "\n",
    "def _build_ragas_metrics(ragas_llm, ragas_emb):\n",
    "    METRICS=[]\n",
    "    ar = _make_answer_relevance_metric(ragas_llm, ragas_emb)\n",
    "    if ar is not None: METRICS.append(ar)\n",
    "    faith = FAITH\n",
    "    if hasattr(faith, \"llm\"): setattr(faith, \"llm\", ragas_llm)\n",
    "    METRICS.append(faith)\n",
    "    if hasattr(RM, \"context_recall\"):    METRICS.append(RM.context_recall)\n",
    "    if hasattr(RM, \"context_precision\"): METRICS.append(RM.context_precision)\n",
    "    return _bind_models_to_metrics(METRICS, ragas_llm, ragas_emb)\n",
    "\n",
    "def _to_ragas_dataset(df: pd.DataFrame):\n",
    "    sdf=df.copy()\n",
    "    sdf[\"contexts\"] = sdf[\"contexts\"].apply(lambda x: list(x) if isinstance(x, (list, tuple)) else ([] if x is None else [str(x)]))\n",
    "    # Preferred: new ragas Dataset\n",
    "    try:\n",
    "        from ragas.dataset import Dataset as RagasDataset, SingleTurnSample\n",
    "        params = set(__import__(\"inspect\").signature(SingleTurnSample).parameters.keys())\n",
    "        samples=[]\n",
    "        for _, row in sdf.iterrows():\n",
    "            kwargs = dict(question=row[\"question\"], answer=row[\"answer\"], contexts=list(row[\"contexts\"]))\n",
    "            if \"reference\" in row and \"reference\" in params:\n",
    "                kwargs[\"reference\"] = row[\"reference\"]\n",
    "            elif \"reference\" in row and \"ground_truth\" in params:\n",
    "                kwargs[\"ground_truth\"] = row[\"reference\"]\n",
    "            samples.append(SingleTurnSample(**kwargs))\n",
    "        return RagasDataset(samples=samples)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback: HF Dataset or raw DataFrame\n",
    "    try:\n",
    "        from datasets import Dataset as HFDataset\n",
    "        return HFDataset.from_pandas(sdf, preserve_index=False)\n",
    "    except Exception:\n",
    "        return sdf\n",
    "\n",
    "def _evaluate_safe(dataset_in, metrics, ragas_llm, ragas_emb):\n",
    "    rc = None\n",
    "    if RunConfig is not None:\n",
    "        try: rc = RunConfig(max_workers=1, timeout=180, max_retries=10, max_wait=60)\n",
    "        except TypeError: rc = RunConfig()\n",
    "    try:\n",
    "        return evaluate(dataset_in, metrics=metrics, llm=ragas_llm, embeddings=ragas_emb,\n",
    "                        show_progress=False, run_config=rc, batch_size=1)\n",
    "    except TypeError:\n",
    "        return evaluate(dataset_in, metrics=metrics, llm=ragas_llm, embeddings=ragas_emb,\n",
    "                        show_progress=False)\n",
    "\n",
    "def _scores_from_result(res) -> Dict[str, float]:\n",
    "    try:\n",
    "        df = res.to_pandas()\n",
    "    except Exception:\n",
    "        df = pd.DataFrame(res)\n",
    "    if isinstance(df, pd.DataFrame) and not df.empty:\n",
    "        nums = {c: float(df[c].iloc[0]) for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and len(df)==1}\n",
    "        if nums: return nums\n",
    "        if {\"metric\",\"score\"}.issubset(df.columns):\n",
    "            out = {}\n",
    "            for k, v in zip(df[\"metric\"], df[\"score\"]):\n",
    "                try: out[str(k)] = float(v)\n",
    "                except Exception: pass\n",
    "            if out: return out\n",
    "    return {}\n",
    "\n",
    "def _friendly_scores(d: Dict[str,float]) -> Dict[str,float]:\n",
    "    rename = {\n",
    "        \"answer_relevancy\": \"Answer Relevance\",\n",
    "        \"answer_relevance\": \"Answer Relevance\",\n",
    "        \"faithfulness\": \"Faithfulness (≈ Groundedness)\",\n",
    "        \"context_recall\": \"Context Recall\",\n",
    "        \"context_precision\": \"Context Precision\",\n",
    "        \"context_relevancy\": \"Context Relevance\",\n",
    "    }\n",
    "    return {rename.get(k, k): v for k, v in d.items()}\n",
    "\n",
    "def _has_gold_refs(cfg: Dict[str, Any]) -> bool:\n",
    "    refs = cfg.get(\"eval_references\", []); qs = cfg.get(\"eval_questions\", [])\n",
    "    return isinstance(refs, list) and len(refs) == len(qs) and all(isinstance(x, str) and x.strip() for x in refs)\n",
    "\n",
    "# 4) Main\n",
    "def main(CONFIG: Dict[str, Any]):\n",
    "    assert os.environ.get(\"OPENAI_API_KEY\"), \"Set OPENAI_API_KEY\"\n",
    "    outdir = Path(CONFIG[\"output_dir\"]); outdir.mkdir(parents=True, exist_ok=True)\n",
    "    if CONFIG.get(\"create_sample_if_empty\", True): _maybe_create_sample(CONFIG[\"data_path\"])\n",
    "    docs = _load_corpus(CONFIG[\"data_path\"])\n",
    "\n",
    "    embed_model = _build_embedder(CONFIG[\"embedding\"])\n",
    "    llm = _build_llm(CONFIG[\"llm\"])\n",
    "    Settings.embed_model = embed_model\n",
    "    Settings.llm = llm\n",
    "    client = OpenAIClient()\n",
    "\n",
    "    # Refs for recall/precision\n",
    "    if not _has_gold_refs(CONFIG):\n",
    "        print(\"[INFO] No references provided → auto-generating short references from corpus for recall/precision.\")\n",
    "        sys.stdout.flush()\n",
    "        CONFIG[\"eval_references\"] = _generate_references_from_corpus(docs, CONFIG[\"eval_questions\"], client)\n",
    "\n",
    "    # RAGAS backends\n",
    "    try:\n",
    "        ragas_llm = llm_factory(provider=\"openai\", model=CONFIG[\"ragas\"][\"llm_model\"], client=client)\n",
    "    except TypeError:\n",
    "        try: ragas_llm = llm_factory(model=CONFIG[\"ragas\"][\"llm_model\"], client=client)\n",
    "        except TypeError: ragas_llm = llm_factory(model=CONFIG[\"ragas\"][\"llm_model\"])\n",
    "    ragas_emb = OpenAIEmbeddingsAdapter(client=client, model=CONFIG[\"ragas\"][\"embed_model\"])\n",
    "    METRICS   = _build_ragas_metrics(ragas_llm, ragas_emb)\n",
    "\n",
    "    # Config summary (Markdown)\n",
    "    cfg_view = {\n",
    "        \"embedding\": CONFIG[\"embedding\"][\"model\"],\n",
    "        \"llm\": CONFIG[\"llm\"][\"model\"],\n",
    "        \"ragas_llm\": CONFIG[\"ragas\"][\"llm_model\"],\n",
    "        \"ragas_emb\": CONFIG[\"ragas\"][\"embed_model\"],\n",
    "        \"experiments\": [f\"{e['name']} ({e['retriever']})\" + (\" + rerank\" if e.get('reranker') else \"\") for e in CONFIG[\"experiments\"]],\n",
    "        \"questions\": len(CONFIG[\"eval_questions\"]),\n",
    "        \"references\": \"provided\" if _has_gold_refs(CONFIG) else \"auto-generated\",\n",
    "    }\n",
    "    cfg_md = pd.DataFrame(cfg_view.items(), columns=[\"Key\",\"Value\"]).to_markdown(index=False)\n",
    "    md_table(cfg_md, title=\"### CONFIG\", small=False, bold=False)\n",
    "\n",
    "    print(\"\\n=== TRACES (Question ➜ Answer by experiment) ===\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Warn once if Cohere rerank is configured but unavailable\n",
    "    for exp in CONFIG[\"experiments\"]:\n",
    "        if exp.get(\"reranker\", {}).get(\"type\",\"\").lower() == \"cohere\":\n",
    "            if not (_COHERE_AVAILABLE and os.environ.get(\"COHERE_API_KEY\")):\n",
    "                print(\"[WARN] COHERE_API_KEY not set or 'cohere' not installed → falling back to LLM/embedding reranker.\")\n",
    "\n",
    "    # Build experiments\n",
    "    rows=[]  # for eval + saving\n",
    "    for exp in CONFIG[\"experiments\"]:\n",
    "        name, retr, top_k = exp[\"name\"], exp[\"retriever\"], int(exp.get(\"top_k\", 6))\n",
    "\n",
    "        # retriever\n",
    "        if retr == \"vector\":\n",
    "            retriever, _ = _build_vector_retriever(docs, embed_model, top_k)\n",
    "        elif retr == \"sentence_window\":\n",
    "            retriever, _ = _build_sentence_window_retriever(docs, embed_model, window_size=int(exp.get(\"window_size\", 3)), top_k=top_k)\n",
    "        elif retr == \"auto_merging\":\n",
    "            retriever, _ = _build_auto_merging_retriever(docs, embed_model, top_k)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown retriever: {retr}\")\n",
    "\n",
    "        rer_cfg = exp.get(\"reranker\")\n",
    "        header = f\"--- Experiment: {name}  | retriever={retr}  | rerank={'on' if rer_cfg else 'off'} ---\"\n",
    "        print(f\"\\n{header}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        for i, (q, ref) in enumerate(zip(CONFIG[\"eval_questions\"], CONFIG[\"eval_references\"])):\n",
    "            # retrieve + (optional) rerank\n",
    "            nodes = retriever.retrieve(q)\n",
    "            nodes2 = _apply_rerank(q, nodes, rer_cfg, client) if rer_cfg else nodes[:min(top_k, len(nodes))]\n",
    "            ctx_texts=[]\n",
    "            for sn in nodes2:\n",
    "                n = getattr(sn, \"node\", None) or sn\n",
    "                t = getattr(n, \"text\", None) or getattr(n, \"get_text\", lambda: None)()\n",
    "                if t: ctx_texts.append(t)\n",
    "\n",
    "            # answer (extractive)\n",
    "            ans, ctxs = _answer_extractive(q, ctx_texts, client)\n",
    "\n",
    "            # trace (plain prints, as requested earlier)\n",
    "            print(f\"\\nQ{ i+1 }: {q}\")\n",
    "            print(f\"A{ i+1 }: {ans}\")\n",
    "            print(f\"Ref: {ref}\")\n",
    "            if CONFIG[\"print_context_chars\"] > 0:\n",
    "                maxc = CONFIG[\"print_context_chars\"]\n",
    "                for ci, c in enumerate(ctxs[:5]):\n",
    "                    print(f\"   ctx[{ci}]: {c[:maxc].replace('\\\\n',' ')}{'…' if len(c)>maxc else ''}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            rows.append({\n",
    "                \"experiment\": name,\n",
    "                \"retriever\": retr,\n",
    "                \"question\": q,\n",
    "                \"answer\": ans,\n",
    "                \"contexts\": ctxs,\n",
    "                \"reference\": ref,\n",
    "            })\n",
    "\n",
    "    # ---- Incremental evaluation: one-sample-at-a-time (so you SEE progress) ----\n",
    "    all_rows = pd.DataFrame(rows)\n",
    "    scored_rows = []\n",
    "\n",
    "    md_line(\"### EVALUATION (per-sample progress)\", bold=True)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    for ridx, r in all_rows.iterrows():\n",
    "        sub = pd.DataFrame([r[[\"question\",\"answer\",\"contexts\",\"reference\"]]])\n",
    "        ds  = _to_ragas_dataset(sub)\n",
    "        try:\n",
    "            res = _evaluate_safe(ds, METRICS, ragas_llm, ragas_emb)\n",
    "            scores = _friendly_scores(_scores_from_result(res))\n",
    "        except Exception as e:\n",
    "            scores = {}\n",
    "            md_line(f\"[WARN] Eval failed for '{r['experiment']}' / Q: {r['question'][:48]}… → {e}\", small=True, bold=True)\n",
    "\n",
    "        # per-line feedback in small + bold\n",
    "        parts = [f\"{k}={scores.get(k):.3f}\" for k in [\"Answer Relevance\",\"Faithfulness (≈ Groundedness)\",\"Context Recall\",\"Context Precision\"] if k in scores]\n",
    "        line = f\"• {r['experiment']}  |  {r['question'][:64]}…  |  \" + (\", \".join(parts) if parts else \"no-metrics\")\n",
    "        md_line(line, small=True, bold=True)\n",
    "\n",
    "        # store\n",
    "        row_out = {\"experiment\": r[\"experiment\"], \"retriever\": r[\"retriever\"], \"question\": r[\"question\"]}\n",
    "        for k,v in scores.items(): row_out[k] = v\n",
    "        scored_rows.append(row_out)\n",
    "\n",
    "    scored_df = pd.DataFrame(scored_rows)\n",
    "\n",
    "    # Leaderboard (means) — Markdown\n",
    "    if not scored_df.empty:\n",
    "        metric_cols = [c for c in [\"Answer Relevance\",\"Faithfulness (≈ Groundedness)\",\"Context Recall\",\"Context Precision\"] if c in scored_df.columns]\n",
    "        if metric_cols:\n",
    "            leaderboard = (scored_df.groupby([\"experiment\",\"retriever\"], as_index=False)[metric_cols]\n",
    "                           .mean(numeric_only=True))\n",
    "            md_table(leaderboard.to_markdown(index=False), title=\"### RAGAS Leaderboard (means)\")\n",
    "        else:\n",
    "            leaderboard = scored_df[[\"experiment\",\"retriever\"]].drop_duplicates()\n",
    "            md_table(leaderboard.to_markdown(index=False), title=\"### RAGAS Leaderboard (means)\")\n",
    "    else:\n",
    "        md_line(\"### RAGAS Leaderboard (means)\\n(no scores)\", bold=True)\n",
    "\n",
    "    # Per-question Scores — Markdown\n",
    "    if not scored_df.empty:\n",
    "        cols_show = [\"experiment\",\"retriever\",\"question\"] + [c for c in [\"Answer Relevance\",\"Faithfulness (≈ Groundedness)\",\"Context Recall\",\"Context Precision\"] if c in scored_df.columns]\n",
    "        md_table(scored_df[cols_show].to_markdown(index=False), title=\"### Per-question Scores (Markdown)\")\n",
    "\n",
    "    # --- END: Experiments summary table in Markdown (requested) ---\n",
    "    exp_rows=[]\n",
    "    for e in CONFIG[\"experiments\"]:\n",
    "        row = {\n",
    "            \"Experiment\": e[\"name\"],\n",
    "            \"Retriever\": e[\"retriever\"],\n",
    "            \"TopK\": e.get(\"top_k\", \"\"),\n",
    "            \"Rerank\": \"on\" if e.get(\"reranker\") else \"off\",\n",
    "        }\n",
    "        if e[\"retriever\"] == \"sentence_window\":\n",
    "            row[\"Window\"] = e.get(\"window_size\", \"\")\n",
    "        if e.get(\"reranker\"):\n",
    "            row[\"Reranker Type\"] = e[\"reranker\"].get(\"type\", \"llm\")\n",
    "            row[\"Rerank Model\"] = e[\"reranker\"].get(\"model\", \"\")\n",
    "            row[\"Rerank TopN\"]  = e[\"reranker\"].get(\"top_n\", \"\")\n",
    "        exp_rows.append(row)\n",
    "    exp_df = pd.DataFrame(exp_rows)\n",
    "    md_table(exp_df.to_markdown(index=False), title=\"### Experiments Summary (Markdown)\")\n",
    "\n",
    "    # Save artifacts\n",
    "    out = Path(CONFIG[\"output_dir\"]); out.mkdir(parents=True, exist_ok=True)\n",
    "    all_rows.to_csv(out / \"traces_all.csv\", index=False)\n",
    "    (out / \"traces\").mkdir(exist_ok=True, parents=True)\n",
    "    for exp_name, sub in all_rows.groupby(\"experiment\"):\n",
    "        sub[[\"experiment\",\"retriever\",\"question\",\"answer\",\"contexts\",\"reference\"]].to_csv(out / \"traces\" / f\"{exp_name}.csv\", index=False)\n",
    "    if not scored_df.empty: scored_df.to_csv(out / \"ragas_raw_scores.csv\", index=False)\n",
    "    try:\n",
    "        if \"leaderboard\" in locals() and isinstance(leaderboard, pd.DataFrame) and not leaderboard.empty:\n",
    "            leaderboard.to_csv(out / \"ragas_leaderboard.csv\", index=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(f\"\\n[Saved] traces → {out/'traces_all.csv'}  |  raw scores → {out/'ragas_raw_scores.csv'}  |  leaderboard → {out/'ragas_leaderboard.csv'}\")\n",
    "\n",
    "# 5) Run\n",
    "main(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73b74d-1896-44fe-8b33-b54f5734ee87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
